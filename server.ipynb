{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80433520",
   "metadata": {},
   "source": [
    "# Server.py \n",
    "## Federated Learning Server\n",
    "Accepts connection from a set number of clients. Has access to a repository of unlabeled public data. Once all clients send predictions on public data, server aggregates results. Once resulrs are compiled the server sends out the public dataset to supliment client training with the newly assigned labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db8406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from send_receive import *\n",
    "import socket\n",
    "import threading\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6780a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features():\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    X_train = mnist_trainset.data[50000:,:] #load the last 10,000 images leaving the rest for the clients private data\n",
    "    X_train = X_train.float().flatten(start_dim=1, end_dim=2) # Flatten training images\n",
    "    return X_train\n",
    "\n",
    "def load_labels():\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "    Y_train = mnist_trainset.targets[50000:] #load the last 10,000 images leaving the rest for the clients private data\n",
    "    return Y_train\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 50\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "logits_dict = {}\n",
    "num_responses = 0\n",
    "agreggation_done = 0\n",
    "\n",
    "X_pub = load_features()\n",
    "Y_pub = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ee30cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_median(logits):\n",
    "\n",
    "    mu = logits.median(dim=0).values\n",
    "\n",
    "    return mu\n",
    "\n",
    "def f_cronus(\n",
    "    logits,\n",
    "    eps=1e-3,\n",
    "    lambda_thresh=9.0,\n",
    "    max_iters=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust Cronus aggregation.\n",
    "\n",
    "    logits: Tensor [K, N, C]  (models × samples × classes)\n",
    "    returns: Tensor [N, C]\n",
    "    \"\"\"\n",
    "\n",
    "    K, N, C = logits.shape\n",
    "    device = logits.device\n",
    "\n",
    "    agg = torch.zeros(N, C, device=device)\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        # Y: [K, C] logits for sample n\n",
    "        Y = logits[:, n, :]\n",
    "\n",
    "        # Initial mean\n",
    "        mu = Y.mean(dim=0)\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "\n",
    "            # Centered data\n",
    "            X = Y - mu\n",
    "\n",
    "            # If no disagreement, stop\n",
    "            if X.norm() < 1e-6:\n",
    "                break\n",
    "\n",
    "            # Empirical covariance (rank-deficient-safe)\n",
    "            Sigma = (X.T @ X) / max(len(Y) - 1, 1)\n",
    "\n",
    "            # Diagonal regularization\n",
    "            Sigma = Sigma + eps * torch.eye(C, device=device)\n",
    "\n",
    "            # Eigendecomposition with safety\n",
    "            try:\n",
    "                eigvals, eigvecs = torch.linalg.eigh(Sigma)\n",
    "            except RuntimeError:\n",
    "                # Covariance too ill-conditioned → skip trimming\n",
    "                break\n",
    "\n",
    "            lambda_star = eigvals[-1]\n",
    "\n",
    "            # If largest eigenvalue small enough, stop trimming\n",
    "            if lambda_star <= lambda_thresh:\n",
    "                break\n",
    "\n",
    "            # Principal direction\n",
    "            v_star = eigvecs[:, -1]\n",
    "\n",
    "            # Project samples onto principal direction\n",
    "            projections = torch.abs((Y - mu) @ v_star)\n",
    "\n",
    "            max_proj = projections.max()\n",
    "            if max_proj < 1e-6:\n",
    "                break\n",
    "\n",
    "            # Randomized trimming threshold (Cronus)\n",
    "            T = torch.sqrt(torch.rand(1, device=device)) * max_proj\n",
    "\n",
    "            mask = projections < T\n",
    "\n",
    "            # If too few samples left, stop\n",
    "            if mask.sum() <= 1:\n",
    "                break\n",
    "\n",
    "            # Trim and recompute mean\n",
    "            Y = Y[mask]\n",
    "            mu = Y.mean(dim=0)\n",
    "\n",
    "        agg[n] = mu\n",
    "\n",
    "    return agg\n",
    "\n",
    "def f_cronus_bila(\n",
    "    logits,\n",
    "    eps=1e-3,\n",
    "    lambda_thresh=9.0,\n",
    "    max_iters=5,\n",
    "    beta=5.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Cronus + BiLA hybrid aggregation.\n",
    "\n",
    "    logits: Tensor [K, N, C]  (models × samples × classes)\n",
    "    returns: Tensor [N, C]    (aggregated logits)\n",
    "\n",
    "    beta: sharpness of reliability weighting\n",
    "    \"\"\"\n",
    "\n",
    "    K, N, C = logits.shape\n",
    "    device = logits.device\n",
    "\n",
    "    agg = torch.zeros(N, C, device=device)\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        # ---- Step 1: Cronus trimming (logit space) ----\n",
    "        Y = logits[:, n, :]          # [K, C]\n",
    "        mu = Y.mean(dim=0)\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "\n",
    "            X = Y - mu\n",
    "            if X.norm() < 1e-6:\n",
    "                break\n",
    "\n",
    "            Sigma = (X.T @ X) / max(len(Y) - 1, 1)\n",
    "            Sigma = Sigma + eps * torch.eye(C, device=device)\n",
    "\n",
    "            try:\n",
    "                eigvals, eigvecs = torch.linalg.eigh(Sigma)\n",
    "            except RuntimeError:\n",
    "                break\n",
    "\n",
    "            if eigvals[-1] <= lambda_thresh:\n",
    "                break\n",
    "\n",
    "            v = eigvecs[:, -1]\n",
    "            proj = torch.abs((Y - mu) @ v)\n",
    "\n",
    "            T = torch.sqrt(torch.rand(1, device=device)) * proj.max()\n",
    "            mask = proj < T\n",
    "\n",
    "            if mask.sum() <= 1:\n",
    "                break\n",
    "\n",
    "            Y = Y[mask]\n",
    "            mu = Y.mean(dim=0)\n",
    "\n",
    "        # ---- Step 2: BiLA-style reliability weighting ----\n",
    "        # Reliability = agreement with trimmed mean\n",
    "        distances = torch.norm(Y - mu, dim=1)          # [K']\n",
    "        weights = torch.exp(-beta * distances)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        # ---- Step 3: weighted aggregation ----\n",
    "        agg[n] = (weights[:, None] * Y).sum(dim=0)\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a4c07ef-39ec-49f6-89ff-3ec383d0fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLACMAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Stateful BiLA-CM aggregator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_models, num_classes, hidden_dim=64, lr=1e-3, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.K = num_models\n",
    "        self.C = num_classes\n",
    "        self.device = device\n",
    "\n",
    "        # α network\n",
    "        self.W1 = nn.Linear(self.C, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, self.C)\n",
    "\n",
    "        # β confusion matrices\n",
    "        self.pi = nn.Parameter(\n",
    "            torch.ones(self.K, self.C, self.C) / self.C\n",
    "        )\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    def update(self, logits, epochs=5):\n",
    "        \"\"\"\n",
    "        logits: [K, N, C] (already trimmed!)\n",
    "        returns: aggregated labels [N, C]\n",
    "        \"\"\"\n",
    "\n",
    "        K, N, C = logits.shape\n",
    "        assert K == self.K and C == self.C\n",
    "\n",
    "        logits = logits.to(self.device)\n",
    "        model_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # α prior\n",
    "            mean_probs = model_probs.mean(dim=0)        # [N, C]\n",
    "            h = torch.tanh(self.W1(mean_probs))\n",
    "            q_alpha = F.softmax(self.W2(h), dim=-1)\n",
    "\n",
    "            # β likelihood\n",
    "            log_likelihood = torch.zeros(N, C, device=self.device)\n",
    "\n",
    "            for k in range(K):\n",
    "                pi_k = F.softmax(self.pi[k], dim=-1)\n",
    "                log_likelihood += torch.log(\n",
    "                    model_probs[k] @ pi_k.T + 1e-8\n",
    "                )\n",
    "\n",
    "            log_post = torch.log(q_alpha + 1e-8) + log_likelihood\n",
    "            Y_hat = F.softmax(log_post, dim=-1)\n",
    "\n",
    "            loss = -(Y_hat * log_post).sum(dim=1).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.infer(logits)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def infer(self, logits):\n",
    "        \"\"\"\n",
    "        Inference only (no learning)\n",
    "        \"\"\"\n",
    "        logits = logits.to(self.device)\n",
    "        model_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        mean_probs = model_probs.mean(dim=0)\n",
    "        h = torch.tanh(self.W1(mean_probs))\n",
    "        q_alpha = F.softmax(self.W2(h), dim=-1)\n",
    "\n",
    "        log_likelihood = torch.zeros(mean_probs.shape[0], self.C, device=self.device)\n",
    "        for k in range(self.K):\n",
    "            pi_k = F.softmax(self.pi[k], dim=-1)\n",
    "            log_likelihood += torch.log(\n",
    "                model_probs[k] @ pi_k.T + 1e-8\n",
    "            )\n",
    "\n",
    "        log_post = torch.log(q_alpha + 1e-8) + log_likelihood\n",
    "        return F.softmax(log_post, dim=-1)\n",
    "\n",
    "class CronusBiLAAggregator:\n",
    "    def __init__(self, bila):\n",
    "        self.bila = bila\n",
    "\n",
    "    def update(self, logits):\n",
    "        \"\"\"\n",
    "        logits: [K, N, C]\n",
    "        \"\"\"\n",
    "        trimmed_logits = f_cronus(logits)      # [N, C]\n",
    "        trimmed_logits = trimmed_logits.unsqueeze(0).repeat(\n",
    "            self.bila.K, 1, 1\n",
    "        )\n",
    "        return self.bila.update(trimmed_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e1d57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_client(conn, addr, aggregator):\n",
    "    X_pub = load_features()\n",
    "    print(f\"[+] Connected: {addr}\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        bila = BiLACMAggregator(\n",
    "            num_models=NUM_CLIENTS,\n",
    "            num_classes=10,\n",
    "            lr=1e-3,\n",
    "            device=device\n",
    "        ).to(device)\n",
    "        \n",
    "        aggregatorr = CronusBiLAAggregator(bila)\n",
    "\n",
    "        # SEND PUBLIC DATA\n",
    "        send_tensor(conn, X_pub)\n",
    "        \n",
    "        for r in range(NUM_ROUNDS+1):\n",
    "\n",
    "            print(f\"Round {r} Aggregation\")\n",
    "\n",
    "            logits = recv_tensor(conn)\n",
    "\n",
    "            #aggregate_logits = aggregatorr.update(logits)\n",
    "            \n",
    "            aggregate_logits = aggregator(logits)\n",
    "\n",
    "            print(\n",
    "                aggregate_logits.min().item(),\n",
    "                aggregate_logits.max().item(),\n",
    "                aggregate_logits.std().item()\n",
    "            )\n",
    "\n",
    "\n",
    "            send_tensor(conn, aggregate_logits)\n",
    "\n",
    "            print(aggregate_logits.shape)\n",
    "            print(aggregate_logits[-1])\n",
    "\n",
    "    except ConnectionResetError:\n",
    "        print(f\"[-] Connection reset by {addr}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(f\"[-] Disconnected: {addr}\")\n",
    "\n",
    "def start_server(HOST, PORT):\n",
    "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    server.bind((HOST, PORT))\n",
    "    server.listen()\n",
    "\n",
    "    print(f\"[SERVER] Listening on {HOST}:{PORT}\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            conn, addr = server.accept()\n",
    "            thread = threading.Thread(\n",
    "                target=handle_client,\n",
    "                args=(conn, addr, f_cronus),\n",
    "                daemon=True\n",
    "            )\n",
    "            thread.start()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[SERVER] Shutdown requested (Ctrl+C)\")\n",
    "\n",
    "    finally:\n",
    "        server.close()\n",
    "        print(\"[SERVER] Socket closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda9a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Listening on localhost:65435\n",
      "[+] Connected: ('127.0.0.1', 53054)\n",
      "Round 0 Aggregation\n",
      "-18.526174545288086 29.712066650390625 5.030490398406982\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 1.5993, -2.6973,  0.2837, -1.9181, -0.4026,  1.7058, -1.8876,  0.4350,\n",
      "         7.2955,  2.8986])\n",
      "Round 1 Aggregation\n",
      "-19.46892547607422 33.65013885498047 5.060451984405518\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.3316, -3.7999, -0.9993, -0.6673, -1.1489,  2.3024, -1.5566,  0.2128,\n",
      "         6.5410,  2.6132])\n",
      "Round 2 Aggregation\n",
      "-18.50763511657715 32.01768493652344 5.062962532043457\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 1.8491, -1.8711,  1.5974, -2.1387, -1.4464,  1.9788, -1.7829,  1.3851,\n",
      "         7.4017,  3.4867])\n",
      "Round 3 Aggregation\n",
      "-22.22128677368164 30.03365707397461 5.071204662322998\n",
      "torch.Size([10000, 10])\n",
      "tensor([-1.5020, -4.2646, -1.5978, -0.1891, -2.4775,  2.5669, -1.6420,  0.4172,\n",
      "         6.6001,  2.5744])\n",
      "Round 4 Aggregation\n",
      "-18.984630584716797 31.97455596923828 5.079565048217773\n",
      "torch.Size([10000, 10])\n",
      "tensor([-2.0281, -5.7399, -1.9501, -6.0593, -3.5877,  0.0793, -4.3127, -2.7264,\n",
      "         8.1239,  3.2428])\n",
      "Round 5 Aggregation\n",
      "-19.47709846496582 29.764379501342773 5.0926103591918945\n",
      "torch.Size([10000, 10])\n",
      "tensor([-1.9814, -5.7567, -1.9068, -5.6481, -3.6991,  0.4270, -4.5112, -2.7563,\n",
      "         8.2164,  3.2259])\n",
      "Round 6 Aggregation\n",
      "-24.66836929321289 32.815574645996094 5.092606544494629\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.9267, -3.4075, -0.9528, -0.6805, -0.9816,  2.7021, -1.3241,  0.2822,\n",
      "         5.9547,  2.2817])\n",
      "Round 7 Aggregation\n",
      "-19.524169921875 30.423648834228516 5.082331657409668\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.3644, -4.1604, -1.3959, -2.4466, -2.5945,  2.4415, -3.0143, -2.0135,\n",
      "         7.3860,  2.7391])\n",
      "Round 8 Aggregation\n",
      "-19.95801544189453 30.573307037353516 5.0807414054870605\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 2.5255, -2.6417, -2.1113,  0.1724, -1.4712,  5.7582, -0.9477, -2.8727,\n",
      "         4.3721,  0.1135])\n",
      "Round 9 Aggregation\n",
      "-19.93301773071289 29.999366760253906 5.050490379333496\n",
      "torch.Size([10000, 10])\n",
      "tensor([-2.9280, -3.9757, -2.4487, -1.3833, -4.6651,  2.6226, -3.8419, -1.1956,\n",
      "         7.5937,  2.6477])\n",
      "Round 10 Aggregation\n",
      "-19.098098754882812 29.72852897644043 5.025742530822754\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 1.9637, -2.4783, -0.1557, -2.2229,  0.0882,  1.9391, -1.7441,  0.2592,\n",
      "         6.5254,  3.0345])\n",
      "Round 11 Aggregation\n",
      "-22.71953582763672 31.114219665527344 4.909138202667236\n",
      "torch.Size([10000, 10])\n",
      "tensor([-0.8829, -4.5367, -0.9208, -2.9068, -2.6913,  2.1836, -3.1760, -1.3484,\n",
      "         6.8158,  2.6922])\n",
      "Round 12 Aggregation\n",
      "-18.89423179626465 28.920347213745117 4.8736252784729\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.9534, -3.1625, -2.1795, -2.1129, -1.6619,  1.8021, -2.3669, -1.2890,\n",
      "         6.5813,  0.6898])\n",
      "Round 13 Aggregation\n",
      "-19.781007766723633 30.292028427124023 4.826267242431641\n",
      "torch.Size([10000, 10])\n",
      "tensor([-0.3421, -3.4334, -0.8508, -2.9635, -2.7313,  1.6660, -2.8448, -0.2349,\n",
      "         6.4396,  2.0929])\n",
      "Round 14 Aggregation\n",
      "-19.435283660888672 29.395774841308594 4.74673318862915\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.8936, -2.1757, -2.7179,  0.3196, -0.6501,  1.5027, -2.2087,  0.7230,\n",
      "         4.2021,  0.6877])\n",
      "Round 15 Aggregation\n",
      "-20.669567108154297 33.03062057495117 4.78436279296875\n",
      "torch.Size([10000, 10])\n",
      "tensor([ 0.3023, -3.1662, -1.8906, -2.0231, -2.1934,  1.9672, -2.7060, -1.5662,\n",
      "         5.6371,  0.3730])\n",
      "Round 16 Aggregation\n"
     ]
    }
   ],
   "source": [
    "HOST = \"localhost\"\n",
    "PORT = 65435\n",
    "start_server(HOST, PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd53db1-8453-4197-8fdc-f4fd6556e5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
