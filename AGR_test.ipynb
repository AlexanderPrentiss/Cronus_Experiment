{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6460dea",
   "metadata": {},
   "source": [
    "### Limit Scope to Only AGR Testing, No Sockets, No Implementation, Just Logits Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "16792262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.datasets as datasets\n",
    "from scipy.stats import norm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7b7858be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "class RunningStats:\n",
    "    \"\"\"\n",
    "    Tracks running mean and covariance of vectors in R^C\n",
    "    using online (streaming) updates.\n",
    "\n",
    "    This is purely observational — no modification of inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, device=\"cpu\", eps=1e-6):\n",
    "        self.dim = dim\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "\n",
    "        self.n = 0\n",
    "        self.mean = torch.zeros(dim, device=device)\n",
    "        self.M2 = torch.zeros(dim, dim, device=device)  # sum of outer products\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (C,)\n",
    "        \"\"\"\n",
    "        self.n += 1\n",
    "        delta = x - self.mean\n",
    "        self.mean += delta / self.n\n",
    "        delta2 = x - self.mean\n",
    "        self.M2 += torch.outer(delta, delta2)\n",
    "\n",
    "    def covariance(self):\n",
    "        if self.n < 2:\n",
    "            return torch.eye(self.dim, device=self.device) * self.eps\n",
    "        return self.M2 / (self.n - 1) + self.eps * torch.eye(self.dim, device=self.device)\n",
    "\n",
    "    def principal_eigensystem(self):\n",
    "        Sigma = self.covariance()\n",
    "        eigvals, eigvecs = torch.linalg.eigh(Sigma)\n",
    "        return eigvals[-1], eigvecs[:, -1]\n",
    "\n",
    "    def std(self):\n",
    "        \"\"\"Per-class std (shape: C)\"\"\"\n",
    "        return torch.sqrt(torch.diag(self.covariance()))\n",
    "\n",
    "\n",
    "class PublicPredictionObserver:\n",
    "    \"\"\"\n",
    "    Observes public predictions over rounds and maintains\n",
    "    per-sample statistics if desired.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, device=\"cpu\"):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.stats = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.stats = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def observe(self, predictions):\n",
    "        \"\"\"\n",
    "        predictions: Tensor of shape (N, C)\n",
    "        \"\"\"\n",
    "        N, C = predictions.shape\n",
    "        assert C == self.num_classes\n",
    "\n",
    "        if self.stats is None:\n",
    "            self.stats = [\n",
    "                RunningStats(C, device=self.device)\n",
    "                for _ in range(N)\n",
    "            ]\n",
    "\n",
    "        for i in range(N):\n",
    "            self.stats[i].update(predictions[i])\n",
    "\n",
    "    def mean(self):\n",
    "        return torch.stack([s.mean for s in self.stats])\n",
    "    \n",
    "    def std(self):\n",
    "        return torch.stack([s.std() for s in self.stats])\n",
    "    \n",
    "    def covariance(self, idx):\n",
    "        \"\"\"\n",
    "        Covariance for a specific public sample\n",
    "        \"\"\"\n",
    "        return self.stats[idx].covariance()\n",
    "\n",
    "    def dominant_direction(self, idx):\n",
    "        return self.stats[idx].principal_eigensystem()\n",
    "\n",
    "    \n",
    "def inv_phi(n):\n",
    "    if not (0.0 < n < 1.0):\n",
    "        raise ValueError(\"n must be in (0, 1)\")\n",
    "    return norm.ppf(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "959ca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BENIGN CLIENT\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(784, 256)\n",
    "        self.lin2 = nn.Linear(256, 64)\n",
    "        self.lin3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6d6a35b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MALICIOUS CLIENT\n",
    "class LIE_Model(nn.Module):\n",
    "    def __init__(self, active_round, num_malicious, num_models, observer):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(784, 256)\n",
    "        self.lin2 = nn.Linear(256, 64)\n",
    "        self.lin3 = nn.Linear(64, 10)\n",
    "        self.active_round = active_round\n",
    "        self.num_rounds = 0\n",
    "        self.observer = observer\n",
    "        self.num_malicious = num_malicious\n",
    "        self.num_models= num_models\n",
    "\n",
    "    def calculate_v(self):\n",
    "        mu = self.observer.mean()      \n",
    "        sigma = self.observer.std()     \n",
    "        z = inv_phi(1.0 - self.num_malicious / self.num_models)\n",
    "        v = mu - z * sigma\n",
    "\n",
    "        return v\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training and self.num_rounds > self.active_round:\n",
    "            return self.calculate_v()\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return self.lin3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5f47568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ce_fullbatch(model, X, y, optimizer, epochs):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def train_distill_fullbatch(model, X_pub, teacher_probs, optimizer, epochs, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Distill using teacher probability vectors (Cronus shares prediction vectors).\n",
    "    Minimize KL(teacher || student) equivalent to cross-entropy with soft targets.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        student_logits = model(X_pub)\n",
    "        student_log_probs = F.log_softmax(student_logits, dim=1)\n",
    "        # KLDivLoss expects log-probs input and probs target\n",
    "        loss = F.kl_div(student_log_probs, teacher_probs.clamp_min(eps), reduction=\"batchmean\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs(model, X):\n",
    "    model.eval()\n",
    "    probs = F.softmax(model(X), dim=1)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits(model, X):\n",
    "    model.eval()\n",
    "    return model(X)\n",
    "\n",
    "# -----------------------------\n",
    "# Cronus aggregation (Algorithm 6) + practical modifications used in evaluation\n",
    "# - stop when lambda_star <= 9\n",
    "# - deterministic filtering: remove eps/2 fraction each iteration\n",
    "# - repeat filtering 2 times\n",
    "# -----------------------------\n",
    "def cronus_aggregate_probs(\n",
    "    probs_KNC: torch.Tensor,\n",
    "    eps: float,\n",
    "    lambda_thresh: float = 9.0,\n",
    "    iters: int = 2,\n",
    "    jitter: float = 1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    probs_KNC: (K, N, C) prediction vectors (probabilities) from K parties\n",
    "    returns:   (N, C) aggregated prediction vectors\n",
    "\n",
    "    Implements Algorithm 6's core idea per public sample, and the paper's\n",
    "    practical variant (deterministic eps/2 filtering, 2 iterations). :contentReference[oaicite:6]{index=6}\n",
    "    \"\"\"\n",
    "    K, N, C = probs_KNC.shape\n",
    "    out = torch.empty((N, C), device=probs_KNC.device, dtype=probs_KNC.dtype)\n",
    "\n",
    "    for n in range(N):\n",
    "        Y = probs_KNC[:, n, :]  # (K, C)\n",
    "\n",
    "        # Filtering loop (constant 2 iterations in evaluation) :contentReference[oaicite:7]{index=7}\n",
    "        for _ in range(iters):\n",
    "            mu = Y.mean(dim=0)\n",
    "\n",
    "            X = Y - mu\n",
    "            Sigma = (X.T @ X) / max(Y.shape[0] - 1, 1)\n",
    "            Sigma = Sigma + jitter * torch.eye(C, device=Y.device, dtype=Y.dtype)\n",
    "\n",
    "            eigvals, eigvecs = torch.linalg.eigh(Sigma)\n",
    "            lambda_star = eigvals[-1]\n",
    "            v_star = eigvecs[:, -1]\n",
    "\n",
    "            # Stop condition lambda* <= 9 :contentReference[oaicite:8]{index=8}\n",
    "            if lambda_star <= lambda_thresh:\n",
    "                break\n",
    "\n",
    "            # Deterministic filtering: remove eps/2 fraction farthest along v* :contentReference[oaicite:9]{index=9}\n",
    "            projections = torch.abs((Y - mu) @ v_star)  # (|Y|,)\n",
    "            m = Y.shape[0]\n",
    "\n",
    "            drop_frac = eps / 2.0\n",
    "            drop = int(math.floor(drop_frac * m))\n",
    "\n",
    "            # If drop would kill the set, stop early\n",
    "            if drop <= 0 or (m - drop) < 2:\n",
    "                break\n",
    "\n",
    "            # Keep the points with smallest projections\n",
    "            keep_idx = torch.argsort(projections)[: (m - drop)]\n",
    "            Y = Y[keep_idx]\n",
    "\n",
    "        out[n] = Y.mean(dim=0)\n",
    "\n",
    "    # Keep it a valid probability vector (numerical cleanup)\n",
    "    out = out.clamp_min(0.0)\n",
    "    out = out / (out.sum(dim=1, keepdim=True) + 1e-12)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2b571e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Initialization\n",
    "observer = PublicPredictionObserver(num_classes=10, device=device)\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_test  = datasets.MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "X_train = mnist_train.data[:50000].float().flatten(1).to(device)\n",
    "Y_train = mnist_train.targets[:50000].to(device)\n",
    "\n",
    "X_pub = mnist_train.data[50000:].float().flatten(1).to(device)\n",
    "Y_pub = mnist_train.targets[50000:].to(device)\n",
    "\n",
    "X_test = mnist_test.data.float().flatten(1).to(device)\n",
    "Y_test = mnist_test.targets.to(device)\n",
    "\n",
    "NUM_PARTIES = 28       \n",
    "T1 = 50           \n",
    "T2 = 100             \n",
    "eps_adv = 0.1           \n",
    "lambda_thresh = 9.0 \n",
    "agg_iters = 2   \n",
    "NUM_LIE = 0\n",
    "NUM_LABEL_FLIP = 3\n",
    "LABEL_FLIP_TARGET = 5\n",
    "\n",
    "if NUM_LIE > 0 and NUM_LABEL_FLIP > 0:\n",
    "    raise Exception(\"Cannot have LIE and Label Flip attacks at the same time\")\n",
    "     \n",
    "\n",
    "# Split private data across parties (simple IID split)\n",
    "per_party = len(X_train) // NUM_PARTIES\n",
    "perm = torch.randperm(len(X_train), device=device)\n",
    "\n",
    "X_parts = []\n",
    "Y_parts = []\n",
    "for i in range(NUM_PARTIES):\n",
    "    idx = perm[i * per_party : (i + 1) * per_party]\n",
    "    X_parts.append(X_train[idx])\n",
    "    Y_parts.append(Y_train[idx])\n",
    "\n",
    "if NUM_LABEL_FLIP > 0:\n",
    "    for i in range(NUM_LABEL_FLIP):\n",
    "        Y_parts[i][:] = LABEL_FLIP_TARGET \n",
    "\n",
    "if NUM_LIE > 0:\n",
    "    models = [LIE_Model(active_round=1, num_malicious=NUM_LIE, num_models=NUM_PARTIES, observer=observer).to(device) for _ in range(0,NUM_LIE)]\n",
    "    models = models + [MnistModel().to(device) for _ in range(NUM_LIE,NUM_PARTIES)]\n",
    "else:\n",
    "    models =  [MnistModel().to(device) for _ in range(NUM_LIE,NUM_PARTIES)]\n",
    "# --- Initialization phase (private-only, Adam lr=0.0005) :contentReference[oaicite:11]{index=11}\n",
    "for i in range(NUM_PARTIES):\n",
    "    opt = Adam(models[i].parameters(), lr=5e-4)\n",
    "    train_ce_fullbatch(models[i], X_parts[i], Y_parts[i], opt, epochs=T1)\n",
    "\n",
    "# Initial predictions on public set (Y^0_i = PREDICT(theta_i; Xp)) :contentReference[oaicite:12]{index=12}\n",
    "with torch.no_grad():\n",
    "    probs_stack = torch.stack([predict_probs(m, X_pub) for m in models], dim=0)  # (K,N,C)\n",
    "Y_bar = cronus_aggregate_probs(probs_stack, eps=eps_adv, lambda_thresh=lambda_thresh, iters=agg_iters)\n",
    "observer.observe(Y_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dba79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cronus] epoch 00 | public error 0.0630\n",
      "[Cronus] epoch 01 | public error 0.0592\n",
      "[Cronus] epoch 02 | public error 0.0589\n",
      "[Cronus] epoch 03 | public error 0.0590\n",
      "[Cronus] epoch 04 | public error 0.0591\n",
      "[Cronus] epoch 05 | public error 0.0596\n",
      "[Cronus] epoch 06 | public error 0.0599\n",
      "[Cronus] epoch 07 | public error 0.0594\n",
      "[Cronus] epoch 08 | public error 0.0593\n",
      "[Cronus] epoch 09 | public error 0.0589\n",
      "[Cronus] epoch 10 | public error 0.0588\n",
      "[Cronus] epoch 11 | public error 0.0590\n",
      "[Cronus] epoch 12 | public error 0.0590\n",
      "[Cronus] epoch 13 | public error 0.0590\n",
      "[Cronus] epoch 14 | public error 0.0590\n",
      "[Cronus] epoch 15 | public error 0.0591\n",
      "[Cronus] epoch 16 | public error 0.0592\n",
      "[Cronus] epoch 17 | public error 0.0593\n",
      "[Cronus] epoch 18 | public error 0.0594\n",
      "[Cronus] epoch 19 | public error 0.0594\n",
      "[Cronus] epoch 20 | public error 0.0597\n",
      "[Cronus] epoch 21 | public error 0.0600\n",
      "[Cronus] epoch 22 | public error 0.0596\n",
      "[Cronus] epoch 23 | public error 0.0595\n",
      "[Cronus] epoch 24 | public error 0.0595\n",
      "[Cronus] epoch 25 | public error 0.0598\n",
      "[Cronus] epoch 26 | public error 0.0598\n",
      "[Cronus] epoch 27 | public error 0.0599\n",
      "[Cronus] epoch 28 | public error 0.0599\n",
      "[Cronus] epoch 29 | public error 0.0599\n",
      "[Cronus] epoch 30 | public error 0.0599\n",
      "[Cronus] epoch 31 | public error 0.0602\n",
      "[Cronus] epoch 32 | public error 0.0599\n",
      "[Cronus] epoch 33 | public error 0.0597\n",
      "[Cronus] epoch 34 | public error 0.0598\n",
      "[Cronus] epoch 35 | public error 0.0597\n",
      "[Cronus] epoch 36 | public error 0.0596\n",
      "[Cronus] epoch 37 | public error 0.0597\n",
      "[Cronus] epoch 38 | public error 0.0598\n",
      "[Cronus] epoch 39 | public error 0.0596\n",
      "[Cronus] epoch 40 | public error 0.0597\n",
      "[Cronus] epoch 41 | public error 0.0597\n",
      "[Cronus] epoch 42 | public error 0.0597\n",
      "[Cronus] epoch 43 | public error 0.0598\n",
      "[Cronus] epoch 44 | public error 0.0597\n",
      "[Cronus] epoch 45 | public error 0.0598\n",
      "[Cronus] epoch 46 | public error 0.0598\n",
      "[Cronus] epoch 47 | public error 0.0600\n",
      "[Cronus] epoch 48 | public error 0.0599\n",
      "[Cronus] epoch 49 | public error 0.0601\n",
      "[Cronus] epoch 50 | public error 0.0602\n",
      "[Cronus] epoch 51 | public error 0.0603\n",
      "[Cronus] epoch 52 | public error 0.0602\n",
      "[Cronus] epoch 53 | public error 0.0604\n",
      "[Cronus] epoch 54 | public error 0.0605\n",
      "[Cronus] epoch 55 | public error 0.0607\n",
      "[Cronus] epoch 56 | public error 0.0608\n",
      "[Cronus] epoch 57 | public error 0.0609\n",
      "[Cronus] epoch 58 | public error 0.0609\n",
      "[Cronus] epoch 59 | public error 0.0609\n",
      "[Cronus] epoch 60 | public error 0.0610\n",
      "[Cronus] epoch 61 | public error 0.0611\n",
      "[Cronus] epoch 62 | public error 0.0610\n",
      "[Cronus] epoch 63 | public error 0.0609\n",
      "[Cronus] epoch 64 | public error 0.0611\n",
      "[Cronus] epoch 65 | public error 0.0613\n",
      "[Cronus] epoch 66 | public error 0.0614\n",
      "[Cronus] epoch 67 | public error 0.0614\n",
      "[Cronus] epoch 68 | public error 0.0616\n",
      "[Cronus] epoch 69 | public error 0.0616\n",
      "[Cronus] epoch 70 | public error 0.0617\n",
      "[Cronus] epoch 71 | public error 0.0617\n",
      "[Cronus] epoch 72 | public error 0.0617\n",
      "[Cronus] epoch 73 | public error 0.0617\n",
      "[Cronus] epoch 74 | public error 0.0618\n",
      "[Cronus] epoch 75 | public error 0.0618\n",
      "[Cronus] epoch 76 | public error 0.0618\n",
      "[Cronus] epoch 77 | public error 0.0616\n",
      "[Cronus] epoch 78 | public error 0.0617\n",
      "[Cronus] epoch 79 | public error 0.0617\n",
      "[Cronus] epoch 80 | public error 0.0618\n",
      "[Cronus] epoch 81 | public error 0.0618\n",
      "[Cronus] epoch 82 | public error 0.0618\n",
      "[Cronus] epoch 83 | public error 0.0619\n",
      "[Cronus] epoch 84 | public error 0.0618\n",
      "[Cronus] epoch 85 | public error 0.0618\n",
      "[Cronus] epoch 86 | public error 0.0621\n",
      "[Cronus] epoch 87 | public error 0.0621\n",
      "[Cronus] epoch 88 | public error 0.0621\n",
      "[Cronus] epoch 89 | public error 0.0622\n",
      "[Cronus] epoch 90 | public error 0.0621\n",
      "[Cronus] epoch 91 | public error 0.0621\n",
      "[Cronus] epoch 92 | public error 0.0621\n",
      "[Cronus] epoch 93 | public error 0.0621\n",
      "[Cronus] epoch 94 | public error 0.0622\n",
      "[Cronus] epoch 95 | public error 0.0622\n",
      "[Cronus] epoch 96 | public error 0.0621\n",
      "[Cronus] epoch 97 | public error 0.0621\n",
      "[Cronus] epoch 98 | public error 0.0622\n",
      "[Cronus] epoch 99 | public error 0.0622\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# --- Collaboration phase\n",
    "Epoch = []\n",
    "public_err = []\n",
    "for t in range(T2):\n",
    "    # Each party updates on Di ∪ Dp (paper does private Adam + public SGD) :contentReference[oaicite:13]{index=13}\n",
    "    for i in range(NUM_PARTIES):\n",
    "        opt = SGD(models[i].parameters(), lr=1e-3)\n",
    "        train_ce_fullbatch(models[i], X_parts[i], Y_parts[i], opt, epochs=1)\n",
    "        train_distill_fullbatch(models[i], X_pub, Y_bar.detach(), opt, epochs=1)\n",
    "\n",
    "    # Parties send prediction vectors on Xp; server aggregates to Y_bar^{t+1}\n",
    "    with torch.no_grad():\n",
    "        logits_stack = torch.stack([predict_logits(m, X_pub) for m in models], dim=0)  # (K,N,C)\n",
    "    probs_stack = F.softmax(logits_stack, dim=-1)\n",
    "    Y_bar = cronus_aggregate_probs(probs_stack, eps=eps_adv, lambda_thresh=lambda_thresh, iters=agg_iters)\n",
    "    observer.observe(logits_stack.mean(dim=0))\n",
    "\n",
    "    # Public Data Logging\n",
    "    with torch.no_grad():\n",
    "        cronus_preds = Y_bar.argmax(dim=1)\n",
    "        cronus_err = (cronus_preds != Y_pub).float().mean().item()\n",
    "        print(f\"[Cronus] epoch {t:02d} | public error {cronus_err:.4f}\")\n",
    "\n",
    "    Epoch.append(t)\n",
    "    public_err.append(cronus_err)\n",
    "\n",
    "    # Per Model Logging\n",
    "    # with torch.no_grad():\n",
    "    #     for i in range(NUM_PARTIES):\n",
    "    #         preds = models[i](X_test).argmax(dim=1)\n",
    "    #         err = (preds != Y_test).float().mean().item()\n",
    "    #         print(f\"Collab epoch {t:02d}, party {i}, error {err:.4f}\")\n",
    "\n",
    "    for i in models[0:NUM_LIE]:\n",
    "        i.num_rounds+=1 \n",
    "\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Honors_Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
