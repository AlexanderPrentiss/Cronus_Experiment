{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015d0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# Imports for server connection\n",
    "import socket\n",
    "from send_receive import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec9d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "      super().__init__()\n",
    "      self.lin1 = nn.Linear(784, 256)\n",
    "      self.lin2 = nn.Linear(256, 64)\n",
    "      self.lin3 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, X):\n",
    "      x1 = F.relu(self.lin1(X))\n",
    "      x2 = F.relu(self.lin2(x1))\n",
    "      x3 = self.lin3(x2)\n",
    "      return x3\n",
    "\n",
    "  # Fit function\n",
    "  def fit(self, X, y, optimizer, loss_fn, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "      ypred = self.forward(X)\n",
    "      loss = loss_fn(ypred, y)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70ed0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n"
     ]
    }
   ],
   "source": [
    "# Data fetching\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "# Use first 50,000 entries from mnist training set, rest are for server\n",
    "X_train = mnist_trainset.data[:50000,:]\n",
    "X_train = X_train.float().flatten(start_dim=1, end_dim=2) # Flatten training images\n",
    "Y_train = mnist_trainset.targets[:50000]\n",
    "\n",
    "# Load testsset\n",
    "X_test = mnist_testset.data\n",
    "X_test = X_test.float().flatten(start_dim=1, end_dim=2) # Flatten test images\n",
    "Y_test = mnist_testset.targets\n",
    "\n",
    "#X_train.shape\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59854674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CronusKLLoss(nn.Module):\n",
    "    def __init__(self, T=3.0):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.kl = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits):\n",
    "        student_log_probs = F.log_softmax(student_logits / self.T, dim=1)\n",
    "        teacher_probs     = F.softmax(teacher_logits / self.T, dim=1)\n",
    "        return self.kl(student_log_probs, teacher_probs) * (self.T ** 2)\n",
    "\n",
    "class SoftKLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.kl = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, student_logits, teacher_probs):\n",
    "        student_log_probs = F.log_softmax(student_logits, dim=1)\n",
    "        return self.kl(student_log_probs, teacher_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a96937fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import socket\n",
    "\n",
    "\n",
    "def start_clients(HOST, PORT, num_models, initialization_epochs, collab_epochs):\n",
    "\n",
    "    sampleSize = len(X_train) // num_models\n",
    "    imgSize = len(X_train[0])\n",
    "\n",
    "    X_trains = torch.zeros((sampleSize, imgSize, num_models))\n",
    "    Y_trains = torch.zeros((sampleSize, num_models))\n",
    "\n",
    "    # Fill data for each model\n",
    "    for m in range(num_models):\n",
    "        idx = torch.randperm(len(X_train))[:sampleSize]\n",
    "        X_trains[:, :, m] = X_train[idx]\n",
    "        Y_trains[:, m] = Y_train[idx]\n",
    "\n",
    "    # Socket setup\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.connect((HOST, PORT))\n",
    "    print(f\"Connected to {HOST} on port {PORT}\")\n",
    "\n",
    "    try:\n",
    "        # Receive public features\n",
    "        features = recv_tensor(s)\n",
    "        print(features.shape)\n",
    "    \n",
    "        # Create models\n",
    "        models = [MnistModel() for _ in range(num_models)]\n",
    "    \n",
    "        # INITIALIZATION\n",
    "        optimAdams = [Adam(models[i].parameters(), lr=0.0005) for i in range(num_models)]\n",
    "        for i in range(num_models):\n",
    "            models[i].fit(\n",
    "                X_trains[:, :, i],\n",
    "                Y_trains[:, i].long(),\n",
    "                optimAdams[i],\n",
    "                nn.CrossEntropyLoss(),\n",
    "                initialization_epochs\n",
    "            )\n",
    "    \n",
    "        # Logging\n",
    "        for j in range(num_models):\n",
    "            preds = models[j].forward(X_test).argmax(dim=1)\n",
    "            err = (preds != Y_test).float().mean()\n",
    "            print(f\"Initialization, model {j}, error {err}\")\n",
    "    \n",
    "        # Initial predictions\n",
    "        predictions = torch.stack(\n",
    "            [models[i].forward(features).detach() for i in range(num_models)],\n",
    "            dim=0\n",
    "        )\n",
    "        send_tensor(s, predictions)\n",
    "    \n",
    "        aggregationLabels = recv_tensor(s)\n",
    "        aggregationLabels = F.softmax(aggregationLabels, dim=1)\n",
    "    \n",
    "        # COLLABORATION\n",
    "\n",
    "        optimSGDs = [SGD(models[j].parameters(), lr=0.001) for j in range(num_models)]\n",
    "\n",
    "        optim_hard = [\n",
    "        torch.optim.SGD(models[j].parameters(), lr=0.01)\n",
    "        for j in range(num_models)\n",
    "        ]\n",
    "    \n",
    "        optim_soft = [\n",
    "            torch.optim.SGD(models[j].parameters(), lr=0.001)\n",
    "            for j in range(num_models)\n",
    "        ]\n",
    "        \n",
    "        for t in range(collab_epochs):\n",
    "    \n",
    "            predictions = []\n",
    "    \n",
    "            for j in range(num_models):\n",
    "\n",
    "                # -------- 1. HARD update (anchor) --------\n",
    "                models[j].fit(\n",
    "                    X_trains[:, :, j],\n",
    "                    Y_trains[:, j].long(),\n",
    "                    optim_hard[j],\n",
    "                    nn.CrossEntropyLoss(),\n",
    "                    epochs=1\n",
    "                )\n",
    "            \n",
    "                # -------- 2. SOFT update (regularizer) --------\n",
    "                models[j].fit(\n",
    "                    features,\n",
    "                    aggregationLabels.detach(),\n",
    "                    optim_soft[j],\n",
    "                    SoftKLLoss(),\n",
    "                    epochs=1\n",
    "                )\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                Y_local = F.one_hot(\n",
    "                    Y_trains[..., j].long(),\n",
    "                    num_classes=10\n",
    "                ).float()\n",
    "\n",
    "                X_mix = torch.cat([X_trains[..., j], features])\n",
    "                Y_mix = torch.cat([Y_local, aggregationLabels.detach()])\n",
    "                \n",
    "                models[j].fit(X_mix, Y_mix, optimSGDs[j], SoftKLLoss(), epochs=5)\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                \"\"\"\n",
    "                models[j].fit(X_trains[:, :, j], Y_trains[:, j].long(),\n",
    "                          optimSGD, nn.CrossEntropyLoss(), epochs=5)\n",
    "    \n",
    "                # One-step distillation update\n",
    "                models[j].fit(\n",
    "                    features,\n",
    "                    aggregationLabels.detach(),\n",
    "                    optimSGD,\n",
    "                    CronusKLLoss(T=3.0),\n",
    "                    epochs=1\n",
    "                )\n",
    "                \"\"\"\n",
    "    \n",
    "                predictions.append(models[j].forward(features).detach())\n",
    "    \n",
    "            predictions = torch.stack(predictions, dim=0)\n",
    "            send_tensor(s, predictions)\n",
    "    \n",
    "            aggregationLabels = recv_tensor(s)\n",
    "            aggregationLabels = F.softmax(aggregationLabels, dim=1)\n",
    "    \n",
    "            # Logging\n",
    "            for j in range(num_models):\n",
    "                preds = models[j].forward(X_test).argmax(dim=1)\n",
    "                err = (preds != Y_test).float().mean()\n",
    "                print(f\"Collab step {t}, model {j}, error {err}\")\n",
    "    \n",
    "        print(\"Finished\")\n",
    "    \n",
    "        s.close()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        s.close()\n",
    "        print(\"Keyboard Interrupt, Thread Closed\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "214fd157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to localhost on port 65435\n",
      "torch.Size([10000, 784])\n",
      "Initialization, model 0, error 0.09080000221729279\n",
      "Initialization, model 1, error 0.09390000253915787\n",
      "Initialization, model 2, error 0.10320000350475311\n",
      "Initialization, model 3, error 0.1023000031709671\n",
      "Initialization, model 4, error 0.10289999842643738\n",
      "Initialization, model 5, error 0.09749999642372131\n",
      "Initialization, model 6, error 0.0917000025510788\n",
      "Initialization, model 7, error 0.09870000183582306\n",
      "Initialization, model 8, error 0.09189999848604202\n",
      "Initialization, model 9, error 0.09200000017881393\n",
      "Collab step 0, model 0, error 0.08919999748468399\n",
      "Collab step 0, model 1, error 0.09359999746084213\n",
      "Collab step 0, model 2, error 0.10360000282526016\n",
      "Collab step 0, model 3, error 0.10209999978542328\n",
      "Collab step 0, model 4, error 0.10180000215768814\n",
      "Collab step 0, model 5, error 0.09740000218153\n",
      "Collab step 0, model 6, error 0.09160000085830688\n",
      "Collab step 0, model 7, error 0.09669999778270721\n",
      "Collab step 0, model 8, error 0.09099999815225601\n",
      "Collab step 0, model 9, error 0.0917000025510788\n",
      "Collab step 1, model 0, error 0.08980000019073486\n",
      "Collab step 1, model 1, error 0.09510000050067902\n",
      "Collab step 1, model 2, error 0.10119999945163727\n",
      "Collab step 1, model 3, error 0.10130000114440918\n",
      "Collab step 1, model 4, error 0.10040000081062317\n",
      "Collab step 1, model 5, error 0.09679999947547913\n",
      "Collab step 1, model 6, error 0.09160000085830688\n",
      "Collab step 1, model 7, error 0.09719999879598618\n",
      "Collab step 1, model 8, error 0.09130000323057175\n",
      "Collab step 1, model 9, error 0.09130000323057175\n",
      "Collab step 2, model 0, error 0.08810000121593475\n",
      "Collab step 2, model 1, error 0.09359999746084213\n",
      "Collab step 2, model 2, error 0.10270000249147415\n",
      "Collab step 2, model 3, error 0.10140000283718109\n",
      "Collab step 2, model 4, error 0.09989999979734421\n",
      "Collab step 2, model 5, error 0.09700000286102295\n",
      "Collab step 2, model 6, error 0.09019999951124191\n",
      "Collab step 2, model 7, error 0.09589999914169312\n",
      "Collab step 2, model 8, error 0.08990000188350677\n",
      "Collab step 2, model 9, error 0.09139999747276306\n",
      "Collab step 3, model 0, error 0.08919999748468399\n",
      "Collab step 3, model 1, error 0.09560000151395798\n",
      "Collab step 3, model 2, error 0.10249999910593033\n",
      "Collab step 3, model 3, error 0.10490000247955322\n",
      "Collab step 3, model 4, error 0.09920000284910202\n",
      "Collab step 3, model 5, error 0.09700000286102295\n",
      "Collab step 3, model 6, error 0.09080000221729279\n",
      "Collab step 3, model 7, error 0.09780000150203705\n",
      "Collab step 3, model 8, error 0.09040000289678574\n",
      "Collab step 3, model 9, error 0.09059999883174896\n",
      "Collab step 4, model 0, error 0.08879999816417694\n",
      "Collab step 4, model 1, error 0.09610000252723694\n",
      "Collab step 4, model 2, error 0.10480000078678131\n",
      "Collab step 4, model 3, error 0.10350000113248825\n",
      "Collab step 4, model 4, error 0.09860000014305115\n",
      "Collab step 4, model 5, error 0.0989999994635582\n",
      "Collab step 4, model 6, error 0.08889999985694885\n",
      "Collab step 4, model 7, error 0.09950000047683716\n",
      "Collab step 4, model 8, error 0.08900000154972076\n",
      "Collab step 4, model 9, error 0.09109999984502792\n",
      "Collab step 5, model 0, error 0.08950000256299973\n",
      "Collab step 5, model 1, error 0.10080000013113022\n",
      "Collab step 5, model 2, error 0.10939999669790268\n",
      "Collab step 5, model 3, error 0.11219999939203262\n",
      "Collab step 5, model 4, error 0.1006999984383583\n",
      "Collab step 5, model 5, error 0.10480000078678131\n",
      "Collab step 5, model 6, error 0.08959999680519104\n",
      "Collab step 5, model 7, error 0.10849999636411667\n",
      "Collab step 5, model 8, error 0.08910000324249268\n",
      "Collab step 5, model 9, error 0.09070000052452087\n",
      "Collab step 6, model 0, error 0.09210000187158585\n",
      "Collab step 6, model 1, error 0.1062999963760376\n",
      "Collab step 6, model 2, error 0.11710000038146973\n",
      "Collab step 6, model 3, error 0.11079999804496765\n",
      "Collab step 6, model 4, error 0.09910000115633011\n",
      "Collab step 6, model 5, error 0.10790000110864639\n",
      "Collab step 6, model 6, error 0.08959999680519104\n",
      "Collab step 6, model 7, error 0.11569999903440475\n",
      "Collab step 6, model 8, error 0.0892999991774559\n",
      "Collab step 6, model 9, error 0.09070000052452087\n",
      "Collab step 7, model 0, error 0.09260000288486481\n",
      "Collab step 7, model 1, error 0.11680000275373459\n",
      "Collab step 7, model 2, error 0.1151999980211258\n",
      "Collab step 7, model 3, error 0.1324000060558319\n",
      "Collab step 7, model 4, error 0.10530000180006027\n",
      "Collab step 7, model 5, error 0.12189999967813492\n",
      "Collab step 7, model 6, error 0.09009999781847\n",
      "Collab step 7, model 7, error 0.15279999375343323\n",
      "Collab step 7, model 8, error 0.08869999647140503\n",
      "Collab step 7, model 9, error 0.09260000288486481\n",
      "Collab step 8, model 0, error 0.09529999643564224\n",
      "Collab step 8, model 1, error 0.13040000200271606\n",
      "Collab step 8, model 2, error 0.11949999630451202\n",
      "Collab step 8, model 3, error 0.13220000267028809\n",
      "Collab step 8, model 4, error 0.10119999945163727\n",
      "Collab step 8, model 5, error 0.11999999731779099\n",
      "Collab step 8, model 6, error 0.09220000356435776\n",
      "Collab step 8, model 7, error 0.20579999685287476\n",
      "Collab step 8, model 8, error 0.08990000188350677\n",
      "Collab step 8, model 9, error 0.09359999746084213\n",
      "Collab step 9, model 0, error 0.09730000048875809\n",
      "Collab step 9, model 1, error 0.15780000388622284\n",
      "Collab step 9, model 2, error 0.11860000342130661\n",
      "Collab step 9, model 3, error 0.17000000178813934\n",
      "Collab step 9, model 4, error 0.11590000241994858\n",
      "Collab step 9, model 5, error 0.12319999933242798\n",
      "Collab step 9, model 6, error 0.09520000219345093\n",
      "Collab step 9, model 7, error 0.22040000557899475\n",
      "Collab step 9, model 8, error 0.08980000019073486\n",
      "Collab step 9, model 9, error 0.10159999877214432\n",
      "Collab step 10, model 0, error 0.09740000218153\n",
      "Collab step 10, model 1, error 0.18610000610351562\n",
      "Collab step 10, model 2, error 0.13050000369548798\n",
      "Collab step 10, model 3, error 0.16349999606609344\n",
      "Collab step 10, model 4, error 0.11110000312328339\n",
      "Collab step 10, model 5, error 0.12809999287128448\n",
      "Collab step 10, model 6, error 0.10329999774694443\n",
      "Collab step 10, model 7, error 0.18140000104904175\n",
      "Collab step 10, model 8, error 0.09009999781847\n",
      "Collab step 10, model 9, error 0.10930000245571136\n",
      "Collab step 11, model 0, error 0.10589999705553055\n",
      "Collab step 11, model 1, error 0.210099995136261\n",
      "Collab step 11, model 2, error 0.125900000333786\n",
      "Collab step 11, model 3, error 0.18279999494552612\n",
      "Collab step 11, model 4, error 0.13330000638961792\n",
      "Collab step 11, model 5, error 0.13420000672340393\n",
      "Collab step 11, model 6, error 0.11079999804496765\n",
      "Collab step 11, model 7, error 0.1420000046491623\n",
      "Collab step 11, model 8, error 0.08900000154972076\n",
      "Collab step 11, model 9, error 0.12720000743865967\n",
      "Collab step 12, model 0, error 0.10580000281333923\n",
      "Collab step 12, model 1, error 0.1956000030040741\n",
      "Collab step 12, model 2, error 0.13269999623298645\n",
      "Collab step 12, model 3, error 0.13510000705718994\n",
      "Collab step 12, model 4, error 0.16060000658035278\n",
      "Collab step 12, model 5, error 0.13899999856948853\n",
      "Collab step 12, model 6, error 0.13840000331401825\n",
      "Collab step 12, model 7, error 0.11429999768733978\n",
      "Collab step 12, model 8, error 0.0892999991774559\n",
      "Collab step 12, model 9, error 0.15440000593662262\n",
      "Collab step 13, model 0, error 0.11479999870061874\n",
      "Collab step 13, model 1, error 0.15790000557899475\n",
      "Collab step 13, model 2, error 0.12080000340938568\n",
      "Collab step 13, model 3, error 0.12690000236034393\n",
      "Collab step 13, model 4, error 0.241799995303154\n",
      "Collab step 13, model 5, error 0.14190000295639038\n",
      "Collab step 13, model 6, error 0.14090000092983246\n",
      "Collab step 13, model 7, error 0.1023000031709671\n",
      "Collab step 13, model 8, error 0.08910000324249268\n",
      "Collab step 13, model 9, error 0.19709999859333038\n",
      "Collab step 14, model 0, error 0.12020000070333481\n",
      "Collab step 14, model 1, error 0.12700000405311584\n",
      "Collab step 14, model 2, error 0.11630000174045563\n",
      "Collab step 14, model 3, error 0.1200999990105629\n",
      "Collab step 14, model 4, error 0.2892000079154968\n",
      "Collab step 14, model 5, error 0.14980000257492065\n",
      "Collab step 14, model 6, error 0.16820000112056732\n",
      "Collab step 14, model 7, error 0.09359999746084213\n",
      "Collab step 14, model 8, error 0.08900000154972076\n",
      "Collab step 14, model 9, error 0.2134000062942505\n",
      "Collab step 15, model 0, error 0.15330000221729279\n",
      "Collab step 15, model 1, error 0.10790000110864639\n",
      "Collab step 15, model 2, error 0.10689999908208847\n",
      "Collab step 15, model 3, error 0.11779999732971191\n",
      "Collab step 15, model 4, error 0.23929999768733978\n",
      "Collab step 15, model 5, error 0.18279999494552612\n",
      "Collab step 15, model 6, error 0.13830000162124634\n",
      "Collab step 15, model 7, error 0.08919999748468399\n",
      "Collab step 15, model 8, error 0.0877000018954277\n",
      "Collab step 15, model 9, error 0.16030000150203705\n",
      "Collab step 16, model 0, error 0.1876000016927719\n",
      "Collab step 16, model 1, error 0.10010000318288803\n",
      "Collab step 16, model 2, error 0.09759999811649323\n",
      "Collab step 16, model 3, error 0.11919999867677689\n",
      "Collab step 16, model 4, error 0.18700000643730164\n",
      "Collab step 16, model 5, error 0.21770000457763672\n",
      "Collab step 16, model 6, error 0.11599999666213989\n",
      "Collab step 16, model 7, error 0.0892999991774559\n",
      "Collab step 16, model 8, error 0.0885000005364418\n",
      "Collab step 16, model 9, error 0.10670000314712524\n",
      "Collab step 17, model 0, error 0.19130000472068787\n",
      "Collab step 17, model 1, error 0.09130000323057175\n",
      "Collab step 17, model 2, error 0.09719999879598618\n",
      "Collab step 17, model 3, error 0.11779999732971191\n",
      "Collab step 17, model 4, error 0.14830000698566437\n",
      "Collab step 17, model 5, error 0.18790000677108765\n",
      "Collab step 17, model 6, error 0.09549999982118607\n",
      "Collab step 17, model 7, error 0.0877000018954277\n",
      "Collab step 17, model 8, error 0.08760000020265579\n",
      "Collab step 17, model 9, error 0.10409999638795853\n",
      "Collab step 18, model 0, error 0.16009999811649323\n",
      "Collab step 18, model 1, error 0.0868000015616417\n",
      "Collab step 18, model 2, error 0.09600000083446503\n",
      "Collab step 18, model 3, error 0.11749999970197678\n",
      "Collab step 18, model 4, error 0.1396999955177307\n",
      "Collab step 18, model 5, error 0.12720000743865967\n",
      "Collab step 18, model 6, error 0.08810000121593475\n",
      "Collab step 18, model 7, error 0.0877000018954277\n",
      "Collab step 18, model 8, error 0.08810000121593475\n",
      "Collab step 18, model 9, error 0.09160000085830688\n",
      "Collab step 19, model 0, error 0.14030000567436218\n",
      "Collab step 19, model 1, error 0.08540000021457672\n",
      "Collab step 19, model 2, error 0.10000000149011612\n",
      "Collab step 19, model 3, error 0.11710000038146973\n",
      "Collab step 19, model 4, error 0.11580000072717667\n",
      "Collab step 19, model 5, error 0.10840000212192535\n",
      "Collab step 19, model 6, error 0.08429999649524689\n",
      "Collab step 19, model 7, error 0.08649999648332596\n",
      "Collab step 19, model 8, error 0.08640000224113464\n",
      "Collab step 19, model 9, error 0.08820000290870667\n",
      "Collab step 20, model 0, error 0.131400004029274\n",
      "Collab step 20, model 1, error 0.0843999981880188\n",
      "Collab step 20, model 2, error 0.10119999945163727\n",
      "Collab step 20, model 3, error 0.11599999666213989\n",
      "Collab step 20, model 4, error 0.09830000251531601\n",
      "Collab step 20, model 5, error 0.10360000282526016\n",
      "Collab step 20, model 6, error 0.08470000326633453\n",
      "Collab step 20, model 7, error 0.08540000021457672\n",
      "Collab step 20, model 8, error 0.0869000032544136\n",
      "Collab step 20, model 9, error 0.08569999784231186\n",
      "Collab step 21, model 0, error 0.12139999866485596\n",
      "Collab step 21, model 1, error 0.08299999684095383\n",
      "Collab step 21, model 2, error 0.10989999771118164\n",
      "Collab step 21, model 3, error 0.11900000274181366\n",
      "Collab step 21, model 4, error 0.09430000185966492\n",
      "Collab step 21, model 5, error 0.09780000150203705\n",
      "Collab step 21, model 6, error 0.08240000158548355\n",
      "Collab step 21, model 7, error 0.08510000258684158\n",
      "Collab step 21, model 8, error 0.08609999716281891\n",
      "Collab step 21, model 9, error 0.08460000157356262\n",
      "Collab step 22, model 0, error 0.09910000115633011\n",
      "Collab step 22, model 1, error 0.0828000009059906\n",
      "Collab step 22, model 2, error 0.11550000309944153\n",
      "Collab step 22, model 3, error 0.121799997985363\n",
      "Collab step 22, model 4, error 0.09189999848604202\n",
      "Collab step 22, model 5, error 0.09520000219345093\n",
      "Collab step 22, model 6, error 0.08240000158548355\n",
      "Collab step 22, model 7, error 0.08479999750852585\n",
      "Collab step 22, model 8, error 0.08730000257492065\n",
      "Collab step 22, model 9, error 0.0828000009059906\n",
      "Collab step 23, model 0, error 0.09260000288486481\n",
      "Collab step 23, model 1, error 0.08299999684095383\n",
      "Collab step 23, model 2, error 0.13050000369548798\n",
      "Collab step 23, model 3, error 0.15530000627040863\n",
      "Collab step 23, model 4, error 0.09059999883174896\n",
      "Collab step 23, model 5, error 0.09279999881982803\n",
      "Collab step 23, model 6, error 0.08219999819993973\n",
      "Collab step 23, model 7, error 0.08429999649524689\n",
      "Collab step 23, model 8, error 0.0860000029206276\n",
      "Collab step 23, model 9, error 0.08299999684095383\n",
      "Collab step 24, model 0, error 0.09229999780654907\n",
      "Collab step 24, model 1, error 0.08219999819993973\n",
      "Collab step 24, model 2, error 0.1485999971628189\n",
      "Collab step 24, model 3, error 0.19200000166893005\n",
      "Collab step 24, model 4, error 0.08980000019073486\n",
      "Collab step 24, model 5, error 0.09139999747276306\n",
      "Collab step 24, model 6, error 0.08160000294446945\n",
      "Collab step 24, model 7, error 0.0843999981880188\n",
      "Collab step 24, model 8, error 0.08709999918937683\n",
      "Collab step 24, model 9, error 0.08150000125169754\n",
      "Collab step 25, model 0, error 0.09059999883174896\n",
      "Collab step 25, model 1, error 0.08229999989271164\n",
      "Collab step 25, model 2, error 0.1598999947309494\n",
      "Collab step 25, model 3, error 0.24330000579357147\n",
      "Collab step 25, model 4, error 0.08820000290870667\n",
      "Collab step 25, model 5, error 0.08969999849796295\n",
      "Collab step 25, model 6, error 0.08179999887943268\n",
      "Collab step 25, model 7, error 0.08420000225305557\n",
      "Collab step 25, model 8, error 0.0868000015616417\n",
      "Collab step 25, model 9, error 0.08139999955892563\n",
      "Collab step 26, model 0, error 0.09049999713897705\n",
      "Collab step 26, model 1, error 0.08219999819993973\n",
      "Collab step 26, model 2, error 0.14810000360012054\n",
      "Collab step 26, model 3, error 0.17479999363422394\n",
      "Collab step 26, model 4, error 0.0877000018954277\n",
      "Collab step 26, model 5, error 0.0885000005364418\n",
      "Collab step 26, model 6, error 0.0820000022649765\n",
      "Collab step 26, model 7, error 0.08470000326633453\n",
      "Collab step 26, model 8, error 0.0869000032544136\n",
      "Collab step 26, model 9, error 0.08100000023841858\n",
      "Collab step 27, model 0, error 0.08820000290870667\n",
      "Collab step 27, model 1, error 0.08179999887943268\n",
      "Collab step 27, model 2, error 0.11230000108480453\n",
      "Collab step 27, model 3, error 0.12849999964237213\n",
      "Collab step 27, model 4, error 0.08659999817609787\n",
      "Collab step 27, model 5, error 0.08760000020265579\n",
      "Collab step 27, model 6, error 0.08129999786615372\n",
      "Collab step 27, model 7, error 0.08460000157356262\n",
      "Collab step 27, model 8, error 0.08619999885559082\n",
      "Collab step 27, model 9, error 0.08110000193119049\n",
      "Collab step 28, model 0, error 0.08820000290870667\n",
      "Collab step 28, model 1, error 0.08139999955892563\n",
      "Collab step 28, model 2, error 0.09359999746084213\n",
      "Collab step 28, model 3, error 0.1088000014424324\n",
      "Collab step 28, model 4, error 0.08649999648332596\n",
      "Collab step 28, model 5, error 0.08669999986886978\n",
      "Collab step 28, model 6, error 0.08100000023841858\n",
      "Collab step 28, model 7, error 0.0843999981880188\n",
      "Collab step 28, model 8, error 0.08730000257492065\n",
      "Collab step 28, model 9, error 0.07999999821186066\n",
      "Collab step 29, model 0, error 0.08420000225305557\n",
      "Collab step 29, model 1, error 0.08160000294446945\n",
      "Collab step 29, model 2, error 0.09109999984502792\n",
      "Collab step 29, model 3, error 0.09910000115633011\n",
      "Collab step 29, model 4, error 0.08550000190734863\n",
      "Collab step 29, model 5, error 0.08739999681711197\n",
      "Collab step 29, model 6, error 0.08139999955892563\n",
      "Collab step 29, model 7, error 0.08380000293254852\n",
      "Collab step 29, model 8, error 0.08619999885559082\n",
      "Collab step 29, model 9, error 0.07989999651908875\n",
      "Collab step 30, model 0, error 0.08489999920129776\n",
      "Collab step 30, model 1, error 0.0812000036239624\n",
      "Collab step 30, model 2, error 0.0869000032544136\n",
      "Collab step 30, model 3, error 0.09350000321865082\n",
      "Collab step 30, model 4, error 0.08540000021457672\n",
      "Collab step 30, model 5, error 0.08619999885559082\n",
      "Collab step 30, model 6, error 0.08160000294446945\n",
      "Collab step 30, model 7, error 0.08330000191926956\n",
      "Collab step 30, model 8, error 0.08659999817609787\n",
      "Collab step 30, model 9, error 0.07999999821186066\n",
      "Collab step 31, model 0, error 0.08150000125169754\n",
      "Collab step 31, model 1, error 0.08169999718666077\n",
      "Collab step 31, model 2, error 0.0869000032544136\n",
      "Collab step 31, model 3, error 0.09359999746084213\n",
      "Collab step 31, model 4, error 0.08540000021457672\n",
      "Collab step 31, model 5, error 0.08590000122785568\n",
      "Collab step 31, model 6, error 0.08169999718666077\n",
      "Collab step 31, model 7, error 0.08330000191926956\n",
      "Collab step 31, model 8, error 0.08560000360012054\n",
      "Collab step 31, model 9, error 0.07999999821186066\n",
      "Collab step 32, model 0, error 0.08020000159740448\n",
      "Collab step 32, model 1, error 0.08110000193119049\n",
      "Collab step 32, model 2, error 0.08429999649524689\n",
      "Collab step 32, model 3, error 0.09059999883174896\n",
      "Collab step 32, model 4, error 0.08529999852180481\n",
      "Collab step 32, model 5, error 0.08590000122785568\n",
      "Collab step 32, model 6, error 0.08089999854564667\n",
      "Collab step 32, model 7, error 0.0835999995470047\n",
      "Collab step 32, model 8, error 0.08619999885559082\n",
      "Collab step 32, model 9, error 0.07980000227689743\n",
      "Collab step 33, model 0, error 0.07909999787807465\n",
      "Collab step 33, model 1, error 0.08100000023841858\n",
      "Collab step 33, model 2, error 0.0851999968290329\n",
      "Collab step 33, model 3, error 0.09179999679327011\n",
      "Collab step 33, model 4, error 0.08560000360012054\n",
      "Collab step 33, model 5, error 0.08579999953508377\n",
      "Collab step 33, model 6, error 0.08139999955892563\n",
      "Collab step 33, model 7, error 0.08320000022649765\n",
      "Collab step 33, model 8, error 0.08470000326633453\n",
      "Collab step 33, model 9, error 0.07959999889135361\n",
      "Collab step 34, model 0, error 0.07959999889135361\n",
      "Collab step 34, model 1, error 0.08060000091791153\n",
      "Collab step 34, model 2, error 0.08320000022649765\n",
      "Collab step 34, model 3, error 0.09000000357627869\n",
      "Collab step 34, model 4, error 0.08479999750852585\n",
      "Collab step 34, model 5, error 0.08579999953508377\n",
      "Collab step 34, model 6, error 0.08089999854564667\n",
      "Collab step 34, model 7, error 0.08290000259876251\n",
      "Collab step 34, model 8, error 0.08619999885559082\n",
      "Collab step 34, model 9, error 0.07959999889135361\n",
      "Collab step 35, model 0, error 0.07880000025033951\n",
      "Collab step 35, model 1, error 0.08049999922513962\n",
      "Collab step 35, model 2, error 0.08370000123977661\n",
      "Collab step 35, model 3, error 0.09109999984502792\n",
      "Collab step 35, model 4, error 0.08500000089406967\n",
      "Collab step 35, model 5, error 0.08550000190734863\n",
      "Collab step 35, model 6, error 0.08129999786615372\n",
      "Collab step 35, model 7, error 0.08259999752044678\n",
      "Collab step 35, model 8, error 0.08479999750852585\n",
      "Collab step 35, model 9, error 0.07940000295639038\n",
      "Collab step 36, model 0, error 0.07800000160932541\n",
      "Collab step 36, model 1, error 0.08060000091791153\n",
      "Collab step 36, model 2, error 0.08269999921321869\n",
      "Collab step 36, model 3, error 0.08990000188350677\n",
      "Collab step 36, model 4, error 0.08449999988079071\n",
      "Collab step 36, model 5, error 0.08550000190734863\n",
      "Collab step 36, model 6, error 0.08049999922513962\n",
      "Collab step 36, model 7, error 0.08240000158548355\n",
      "Collab step 36, model 8, error 0.08500000089406967\n",
      "Collab step 36, model 9, error 0.07930000126361847\n",
      "Collab step 37, model 0, error 0.07760000228881836\n",
      "Collab step 37, model 1, error 0.08049999922513962\n",
      "Collab step 37, model 2, error 0.08299999684095383\n",
      "Collab step 37, model 3, error 0.08959999680519104\n",
      "Collab step 37, model 4, error 0.08449999988079071\n",
      "Collab step 37, model 5, error 0.08550000190734863\n",
      "Collab step 37, model 6, error 0.0812000036239624\n",
      "Collab step 37, model 7, error 0.08169999718666077\n",
      "Collab step 37, model 8, error 0.08479999750852585\n",
      "Collab step 37, model 9, error 0.07909999787807465\n",
      "Collab step 38, model 0, error 0.07819999754428864\n",
      "Collab step 38, model 1, error 0.08020000159740448\n",
      "Collab step 38, model 2, error 0.08250000327825546\n",
      "Collab step 38, model 3, error 0.08860000222921371\n",
      "Collab step 38, model 4, error 0.08410000056028366\n",
      "Collab step 38, model 5, error 0.08550000190734863\n",
      "Collab step 38, model 6, error 0.08049999922513962\n",
      "Collab step 38, model 7, error 0.08209999650716782\n",
      "Collab step 38, model 8, error 0.08500000089406967\n",
      "Collab step 38, model 9, error 0.07840000092983246\n",
      "Collab step 39, model 0, error 0.07699999958276749\n",
      "Collab step 39, model 1, error 0.0803999975323677\n",
      "Collab step 39, model 2, error 0.08259999752044678\n",
      "Collab step 39, model 3, error 0.08820000290870667\n",
      "Collab step 39, model 4, error 0.08449999988079071\n",
      "Collab step 39, model 5, error 0.08500000089406967\n",
      "Collab step 39, model 6, error 0.08070000261068344\n",
      "Collab step 39, model 7, error 0.08139999955892563\n",
      "Collab step 39, model 8, error 0.08429999649524689\n",
      "Collab step 39, model 9, error 0.07850000262260437\n",
      "Collab step 40, model 0, error 0.0778999999165535\n",
      "Collab step 40, model 1, error 0.07999999821186066\n",
      "Collab step 40, model 2, error 0.08259999752044678\n",
      "Collab step 40, model 3, error 0.08699999749660492\n",
      "Collab step 40, model 4, error 0.08340000361204147\n",
      "Collab step 40, model 5, error 0.08460000157356262\n",
      "Collab step 40, model 6, error 0.0803999975323677\n",
      "Collab step 40, model 7, error 0.08150000125169754\n",
      "Collab step 40, model 8, error 0.08389999717473984\n",
      "Collab step 40, model 9, error 0.07840000092983246\n",
      "Collab step 41, model 0, error 0.07699999958276749\n",
      "Collab step 41, model 1, error 0.07980000227689743\n",
      "Collab step 41, model 2, error 0.08299999684095383\n",
      "Collab step 41, model 3, error 0.08730000257492065\n",
      "Collab step 41, model 4, error 0.0835999995470047\n",
      "Collab step 41, model 5, error 0.08420000225305557\n",
      "Collab step 41, model 6, error 0.08030000329017639\n",
      "Collab step 41, model 7, error 0.08139999955892563\n",
      "Collab step 41, model 8, error 0.08349999785423279\n",
      "Collab step 41, model 9, error 0.07840000092983246\n",
      "Collab step 42, model 0, error 0.07729999721050262\n",
      "Collab step 42, model 1, error 0.07959999889135361\n",
      "Collab step 42, model 2, error 0.08160000294446945\n",
      "Collab step 42, model 3, error 0.0869000032544136\n",
      "Collab step 42, model 4, error 0.08349999785423279\n",
      "Collab step 42, model 5, error 0.08429999649524689\n",
      "Collab step 42, model 6, error 0.08009999990463257\n",
      "Collab step 42, model 7, error 0.08100000023841858\n",
      "Collab step 42, model 8, error 0.0835999995470047\n",
      "Collab step 42, model 9, error 0.07829999923706055\n",
      "Collab step 43, model 0, error 0.07689999788999557\n",
      "Collab step 43, model 1, error 0.07959999889135361\n",
      "Collab step 43, model 2, error 0.08240000158548355\n",
      "Collab step 43, model 3, error 0.08709999918937683\n",
      "Collab step 43, model 4, error 0.08330000191926956\n",
      "Collab step 43, model 5, error 0.08349999785423279\n",
      "Collab step 43, model 6, error 0.07989999651908875\n",
      "Collab step 43, model 7, error 0.08100000023841858\n",
      "Collab step 43, model 8, error 0.08320000022649765\n",
      "Collab step 43, model 9, error 0.07779999822378159\n",
      "Collab step 44, model 0, error 0.07680000364780426\n",
      "Collab step 44, model 1, error 0.0794999971985817\n",
      "Collab step 44, model 2, error 0.08150000125169754\n",
      "Collab step 44, model 3, error 0.0868000015616417\n",
      "Collab step 44, model 4, error 0.08349999785423279\n",
      "Collab step 44, model 5, error 0.0835999995470047\n",
      "Collab step 44, model 6, error 0.08020000159740448\n",
      "Collab step 44, model 7, error 0.08100000023841858\n",
      "Collab step 44, model 8, error 0.08389999717473984\n",
      "Collab step 44, model 9, error 0.0778999999165535\n",
      "Collab step 45, model 0, error 0.07660000026226044\n",
      "Collab step 45, model 1, error 0.07900000363588333\n",
      "Collab step 45, model 2, error 0.08179999887943268\n",
      "Collab step 45, model 3, error 0.0868000015616417\n",
      "Collab step 45, model 4, error 0.08320000022649765\n",
      "Collab step 45, model 5, error 0.08290000259876251\n",
      "Collab step 45, model 6, error 0.07989999651908875\n",
      "Collab step 45, model 7, error 0.08100000023841858\n",
      "Collab step 45, model 8, error 0.08269999921321869\n",
      "Collab step 45, model 9, error 0.07729999721050262\n",
      "Collab step 46, model 0, error 0.0763000026345253\n",
      "Collab step 46, model 1, error 0.07940000295639038\n",
      "Collab step 46, model 2, error 0.08139999955892563\n",
      "Collab step 46, model 3, error 0.08590000122785568\n",
      "Collab step 46, model 4, error 0.08320000022649765\n",
      "Collab step 46, model 5, error 0.08330000191926956\n",
      "Collab step 46, model 6, error 0.07999999821186066\n",
      "Collab step 46, model 7, error 0.08100000023841858\n",
      "Collab step 46, model 8, error 0.08309999853372574\n",
      "Collab step 46, model 9, error 0.0778999999165535\n",
      "Collab step 47, model 0, error 0.07649999856948853\n",
      "Collab step 47, model 1, error 0.07919999957084656\n",
      "Collab step 47, model 2, error 0.08150000125169754\n",
      "Collab step 47, model 3, error 0.08609999716281891\n",
      "Collab step 47, model 4, error 0.08320000022649765\n",
      "Collab step 47, model 5, error 0.08240000158548355\n",
      "Collab step 47, model 6, error 0.07970000058412552\n",
      "Collab step 47, model 7, error 0.08060000091791153\n",
      "Collab step 47, model 8, error 0.0828000009059906\n",
      "Collab step 47, model 9, error 0.07729999721050262\n",
      "Collab step 48, model 0, error 0.07609999924898148\n",
      "Collab step 48, model 1, error 0.07900000363588333\n",
      "Collab step 48, model 2, error 0.08129999786615372\n",
      "Collab step 48, model 3, error 0.0860000029206276\n",
      "Collab step 48, model 4, error 0.08320000022649765\n",
      "Collab step 48, model 5, error 0.08259999752044678\n",
      "Collab step 48, model 6, error 0.07999999821186066\n",
      "Collab step 48, model 7, error 0.08089999854564667\n",
      "Collab step 48, model 8, error 0.08320000022649765\n",
      "Collab step 48, model 9, error 0.07769999653100967\n",
      "Collab step 49, model 0, error 0.0763000026345253\n",
      "Collab step 49, model 1, error 0.07900000363588333\n",
      "Collab step 49, model 2, error 0.08089999854564667\n",
      "Collab step 49, model 3, error 0.08550000190734863\n",
      "Collab step 49, model 4, error 0.08309999853372574\n",
      "Collab step 49, model 5, error 0.08219999819993973\n",
      "Collab step 49, model 6, error 0.0794999971985817\n",
      "Collab step 49, model 7, error 0.0803999975323677\n",
      "Collab step 49, model 8, error 0.08269999921321869\n",
      "Collab step 49, model 9, error 0.07720000296831131\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Run\n",
    "# -----------------------------\n",
    "HOST = \"localhost\"\n",
    "PORT = 65435\n",
    "\n",
    "num_models = 10\n",
    "initialization_epochs = 50\n",
    "collab_epochs = 50\n",
    "\n",
    "start_clients(\n",
    "    HOST,\n",
    "    PORT,\n",
    "    num_models,\n",
    "    initialization_epochs,\n",
    "    collab_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234e1c6-e5c9-48d9-a6dd-b2f4db73c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
