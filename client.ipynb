{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015d0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# Imports for server connection\n",
    "import socket\n",
    "from send_receive import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec9d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "      super().__init__()\n",
    "      self.lin1 = nn.Linear(784, 256)\n",
    "      self.lin2 = nn.Linear(256, 64)\n",
    "      self.lin3 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, X):\n",
    "      x1 = F.relu(self.lin1(X))\n",
    "      x2 = F.relu(self.lin2(x1))\n",
    "      x3 = self.lin3(x2)\n",
    "      return x3\n",
    "\n",
    "  # Fit function\n",
    "  def fit(self, X, y, optimizer, loss_fn, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "      ypred = self.forward(X)\n",
    "      loss = loss_fn(ypred, y)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ed0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n"
     ]
    }
   ],
   "source": [
    "# Data fetching\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "# Use first 50,000 entries from mnist training set, rest are for server\n",
    "X_train = mnist_trainset.data[:50000,:]\n",
    "X_train = X_train.float().flatten(start_dim=1, end_dim=2) # Flatten training images\n",
    "Y_train = mnist_trainset.targets[:50000]\n",
    "\n",
    "# Load testsset\n",
    "X_test = mnist_testset.data\n",
    "X_test = X_test.float().flatten(start_dim=1, end_dim=2) # Flatten test images\n",
    "Y_test = mnist_testset.targets[:50000]\n",
    "\n",
    "#X_train.shape\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59854674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CronusKLLoss(nn.Module):\n",
    "    def __init__(self, T=3.0):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.kl = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits):\n",
    "        student_log_probs = F.log_softmax(student_logits / self.T, dim=1)\n",
    "        teacher_probs = F.softmax(teacher_logits / self.T, dim=1)\n",
    "        return self.kl(student_log_probs, teacher_probs) * (self.T ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96937fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to localhost on port 65435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imadk/Desktop/Cronus_Experiment/send_receive.py:51: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tensor = torch.from_numpy(array).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n",
      "Initialization, model 0, error 0.0778999999165535\n",
      "Initialization, model 1, error 0.09099999815225601\n",
      "Initialization, model 2, error 0.08470000326633453\n",
      "Collab step 0, model 0, error 0.07909999787807465\n",
      "Collab step 0, model 1, error 0.09009999781847\n",
      "Collab step 0, model 2, error 0.08470000326633453\n",
      "Collab step 1, model 0, error 0.07919999957084656\n",
      "Collab step 1, model 1, error 0.08879999816417694\n",
      "Collab step 1, model 2, error 0.08470000326633453\n",
      "Collab step 2, model 0, error 0.07880000025033951\n",
      "Collab step 2, model 1, error 0.08879999816417694\n",
      "Collab step 2, model 2, error 0.08470000326633453\n",
      "Collab step 3, model 0, error 0.07850000262260437\n",
      "Collab step 3, model 1, error 0.0885000005364418\n",
      "Collab step 3, model 2, error 0.08470000326633453\n",
      "Collab step 4, model 0, error 0.0778999999165535\n",
      "Collab step 4, model 1, error 0.08799999952316284\n",
      "Collab step 4, model 2, error 0.08470000326633453\n",
      "Collab step 5, model 0, error 0.07760000228881836\n",
      "Collab step 5, model 1, error 0.0877000018954277\n",
      "Collab step 5, model 2, error 0.08470000326633453\n",
      "Collab step 6, model 0, error 0.07699999958276749\n",
      "Collab step 6, model 1, error 0.08730000257492065\n",
      "Collab step 6, model 2, error 0.08470000326633453\n",
      "Collab step 7, model 0, error 0.07689999788999557\n",
      "Collab step 7, model 1, error 0.08669999986886978\n",
      "Collab step 7, model 2, error 0.08470000326633453\n",
      "Collab step 8, model 0, error 0.07689999788999557\n",
      "Collab step 8, model 1, error 0.08609999716281891\n",
      "Collab step 8, model 2, error 0.08470000326633453\n",
      "Collab step 9, model 0, error 0.0771000012755394\n",
      "Collab step 9, model 1, error 0.08649999648332596\n",
      "Collab step 9, model 2, error 0.08470000326633453\n",
      "Collab step 10, model 0, error 0.07699999958276749\n",
      "Collab step 10, model 1, error 0.08659999817609787\n",
      "Collab step 10, model 2, error 0.08470000326633453\n",
      "Collab step 11, model 0, error 0.07609999924898148\n",
      "Collab step 11, model 1, error 0.08630000054836273\n",
      "Collab step 11, model 2, error 0.08470000326633453\n",
      "Collab step 12, model 0, error 0.07609999924898148\n",
      "Collab step 12, model 1, error 0.08630000054836273\n",
      "Collab step 12, model 2, error 0.08470000326633453\n",
      "Collab step 13, model 0, error 0.07620000094175339\n",
      "Collab step 13, model 1, error 0.08640000224113464\n",
      "Collab step 13, model 2, error 0.08470000326633453\n",
      "Collab step 14, model 0, error 0.07649999856948853\n",
      "Collab step 14, model 1, error 0.08619999885559082\n",
      "Collab step 14, model 2, error 0.08470000326633453\n",
      "Collab step 15, model 0, error 0.07620000094175339\n",
      "Collab step 15, model 1, error 0.08630000054836273\n",
      "Collab step 15, model 2, error 0.08470000326633453\n",
      "Collab step 16, model 0, error 0.07609999924898148\n",
      "Collab step 16, model 1, error 0.08699999749660492\n",
      "Collab step 16, model 2, error 0.08470000326633453\n",
      "Collab step 17, model 0, error 0.07739999890327454\n",
      "Collab step 17, model 1, error 0.08669999986886978\n",
      "Collab step 17, model 2, error 0.08470000326633453\n",
      "Collab step 18, model 0, error 0.07819999754428864\n",
      "Collab step 18, model 1, error 0.08780000358819962\n",
      "Collab step 18, model 2, error 0.08470000326633453\n",
      "Collab step 19, model 0, error 0.07919999957084656\n",
      "Collab step 19, model 1, error 0.08820000290870667\n",
      "Collab step 19, model 2, error 0.08470000326633453\n",
      "Collab step 20, model 0, error 0.08049999922513962\n",
      "Collab step 20, model 1, error 0.09109999984502792\n",
      "Collab step 20, model 2, error 0.08470000326633453\n",
      "Collab step 21, model 0, error 0.08190000057220459\n",
      "Collab step 21, model 1, error 0.09359999746084213\n",
      "Collab step 21, model 2, error 0.08470000326633453\n",
      "Collab step 22, model 0, error 0.08449999988079071\n",
      "Collab step 22, model 1, error 0.0957999974489212\n",
      "Collab step 22, model 2, error 0.08470000326633453\n",
      "Collab step 23, model 0, error 0.08799999952316284\n",
      "Collab step 23, model 1, error 0.10019999742507935\n",
      "Collab step 23, model 2, error 0.08470000326633453\n",
      "Collab step 24, model 0, error 0.09130000323057175\n",
      "Collab step 24, model 1, error 0.10419999808073044\n",
      "Collab step 24, model 2, error 0.08470000326633453\n",
      "Collab step 25, model 0, error 0.09529999643564224\n",
      "Collab step 25, model 1, error 0.10790000110864639\n",
      "Collab step 25, model 2, error 0.08470000326633453\n",
      "Collab step 26, model 0, error 0.1006999984383583\n",
      "Collab step 26, model 1, error 0.11299999803304672\n",
      "Collab step 26, model 2, error 0.08470000326633453\n",
      "Collab step 27, model 0, error 0.10740000009536743\n",
      "Collab step 27, model 1, error 0.12020000070333481\n",
      "Collab step 27, model 2, error 0.08470000326633453\n",
      "Collab step 28, model 0, error 0.11309999972581863\n",
      "Collab step 28, model 1, error 0.12870000302791595\n",
      "Collab step 28, model 2, error 0.08470000326633453\n",
      "Collab step 29, model 0, error 0.12039999663829803\n",
      "Collab step 29, model 1, error 0.13459999859333038\n",
      "Collab step 29, model 2, error 0.08470000326633453\n",
      "Collab step 30, model 0, error 0.12960000336170197\n",
      "Collab step 30, model 1, error 0.14169999957084656\n",
      "Collab step 30, model 2, error 0.08470000326633453\n",
      "Collab step 31, model 0, error 0.13779999315738678\n",
      "Collab step 31, model 1, error 0.147599995136261\n",
      "Collab step 31, model 2, error 0.08470000326633453\n",
      "Collab step 32, model 0, error 0.14219999313354492\n",
      "Collab step 32, model 1, error 0.15360000729560852\n",
      "Collab step 32, model 2, error 0.08470000326633453\n",
      "Collab step 33, model 0, error 0.14810000360012054\n",
      "Collab step 33, model 1, error 0.15649999678134918\n",
      "Collab step 33, model 2, error 0.08470000326633453\n",
      "Collab step 34, model 0, error 0.15189999341964722\n",
      "Collab step 34, model 1, error 0.15790000557899475\n",
      "Collab step 34, model 2, error 0.08470000326633453\n",
      "Collab step 35, model 0, error 0.15289999544620514\n",
      "Collab step 35, model 1, error 0.15680000185966492\n",
      "Collab step 35, model 2, error 0.08470000326633453\n",
      "Collab step 36, model 0, error 0.15119999647140503\n",
      "Collab step 36, model 1, error 0.15440000593662262\n",
      "Collab step 36, model 2, error 0.08470000326633453\n",
      "Collab step 37, model 0, error 0.14890000224113464\n",
      "Collab step 37, model 1, error 0.15160000324249268\n",
      "Collab step 37, model 2, error 0.08470000326633453\n",
      "Collab step 38, model 0, error 0.14419999718666077\n",
      "Collab step 38, model 1, error 0.14720000326633453\n",
      "Collab step 38, model 2, error 0.08470000326633453\n",
      "Collab step 39, model 0, error 0.14090000092983246\n",
      "Collab step 39, model 1, error 0.14300000667572021\n",
      "Collab step 39, model 2, error 0.08470000326633453\n",
      "Collab step 40, model 0, error 0.13660000264644623\n",
      "Collab step 40, model 1, error 0.1378999948501587\n",
      "Collab step 40, model 2, error 0.08470000326633453\n",
      "Collab step 41, model 0, error 0.13130000233650208\n",
      "Collab step 41, model 1, error 0.13330000638961792\n",
      "Collab step 41, model 2, error 0.08470000326633453\n",
      "Collab step 42, model 0, error 0.12530000507831573\n",
      "Collab step 42, model 1, error 0.12880000472068787\n",
      "Collab step 42, model 2, error 0.08470000326633453\n",
      "Collab step 43, model 0, error 0.11999999731779099\n",
      "Collab step 43, model 1, error 0.12349999696016312\n",
      "Collab step 43, model 2, error 0.08470000326633453\n",
      "Collab step 44, model 0, error 0.1151999980211258\n",
      "Collab step 44, model 1, error 0.11879999935626984\n",
      "Collab step 44, model 2, error 0.08470000326633453\n",
      "Collab step 45, model 0, error 0.10939999669790268\n",
      "Collab step 45, model 1, error 0.1152999997138977\n",
      "Collab step 45, model 2, error 0.08470000326633453\n",
      "Collab step 46, model 0, error 0.10499999672174454\n",
      "Collab step 46, model 1, error 0.1120000034570694\n",
      "Collab step 46, model 2, error 0.08470000326633453\n",
      "Collab step 47, model 0, error 0.10209999978542328\n",
      "Collab step 47, model 1, error 0.1088000014424324\n",
      "Collab step 47, model 2, error 0.08470000326633453\n",
      "Collab step 48, model 0, error 0.09889999777078629\n",
      "Collab step 48, model 1, error 0.10559999942779541\n",
      "Collab step 48, model 2, error 0.08470000326633453\n",
      "Collab step 49, model 0, error 0.09589999914169312\n",
      "Collab step 49, model 1, error 0.10360000282526016\n",
      "Collab step 49, model 2, error 0.08470000326633453\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import socket\n",
    "\n",
    "\n",
    "def start_clients(HOST, PORT, num_models, learning_rounds, local_epochs, collab_epochs):\n",
    "\n",
    "    sampleSize = len(X_train) // num_models\n",
    "    imgSize = len(X_train[0])\n",
    "\n",
    "    X_trains = torch.zeros((sampleSize, imgSize, num_models))\n",
    "    Y_trains = torch.zeros((sampleSize, num_models))\n",
    "\n",
    "    # Fill data for each model\n",
    "    for m in range(num_models):\n",
    "        idx = torch.randperm(len(X_train))[:sampleSize]\n",
    "        X_trains[:, :, m] = X_train[idx]\n",
    "        Y_trains[:, m] = Y_train[idx]\n",
    "\n",
    "    # Socket setup\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.connect((HOST, PORT))\n",
    "    print(f\"Connected to {HOST} on port {PORT}\")\n",
    "\n",
    "    # Receive public features\n",
    "    features = recv_tensor(s)\n",
    "    print(features.shape)\n",
    "\n",
    "    # Create models\n",
    "    models = [MnistModel() for _ in range(num_models)]\n",
    "\n",
    "    # INITIALIZATION\n",
    "    for i in range(num_models):\n",
    "        optimAdam = Adam(models[i].parameters(), lr=0.0005)\n",
    "        models[i].fit(\n",
    "            X_trains[:, :, i],\n",
    "            Y_trains[:, i].long(),\n",
    "            optimAdam,\n",
    "            nn.CrossEntropyLoss(),\n",
    "            local_epochs\n",
    "        )\n",
    "\n",
    "    # Logging\n",
    "    for j in range(num_models):\n",
    "        preds = models[j].forward(X_test).argmax(dim=1)\n",
    "        err = (preds != Y_test).float().mean()\n",
    "        print(f\"Initialization, model {j}, error {err}\")\n",
    "\n",
    "    # Initial predictions\n",
    "    predictions = torch.stack(\n",
    "        [models[i].forward(features).detach() for i in range(num_models)],\n",
    "        dim=0\n",
    "    )\n",
    "    send_tensor(s, predictions)\n",
    "\n",
    "    aggregationLabels = recv_tensor(s)\n",
    "\n",
    "    # COLLABORATION\n",
    "    for t in range(collab_epochs):\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for j in range(num_models-1):\n",
    "\n",
    "            optimSGD = SGD(models[j].parameters(), lr=0.001)\n",
    "\n",
    "            models[j].fit(X_trains[:, :, j], Y_trains[:, j].long(),\n",
    "                      optimSGD, nn.CrossEntropyLoss(), epochs=5)\n",
    "\n",
    "            # One-step distillation update\n",
    "            models[j].fit(\n",
    "                features,\n",
    "                aggregationLabels.detach(),\n",
    "                optimSGD,\n",
    "                CronusKLLoss(T=3.0),\n",
    "                epochs=1\n",
    "            )\n",
    "\n",
    "            predictions.append(models[j].forward(features).detach())\n",
    "\n",
    "        predictions = torch.stack(predictions, dim=0)\n",
    "        send_tensor(s, predictions)\n",
    "\n",
    "        aggregationLabels = recv_tensor(s)\n",
    "\n",
    "        # Logging\n",
    "        for j in range(num_models):\n",
    "            preds = models[j].forward(X_test).argmax(dim=1)\n",
    "            err = (preds != Y_test).float().mean()\n",
    "            print(f\"Collab step {t}, model {j}, error {err}\")\n",
    "\n",
    "    print(\"Finished\")\n",
    "\n",
    "    s.close()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run\n",
    "# -----------------------------\n",
    "HOST = \"localhost\"\n",
    "PORT = 65435\n",
    "\n",
    "num_models = 3\n",
    "learning_rounds = 1\n",
    "local_epochs = 50\n",
    "collab_epochs = 50\n",
    "\n",
    "start_clients(\n",
    "    HOST,\n",
    "    PORT,\n",
    "    num_models,\n",
    "    learning_rounds,\n",
    "    local_epochs,\n",
    "    collab_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fd157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
